{
  "name": "locis",
  "tagline": "A Parallel Spatial Co-location Mining Algorithm Based on MapReduce",
  "body": "# locis\r\nImplementation of  [A Parallel Spatial Co-location Mining Algorithm Based on MapReduce](docs/paper/paper.pdf) paper\r\n\r\n## Setup\r\n\r\n* Download and setup Scala, Hadoop (with HDFS) and HBase for versions given [here](docs/implementation.md).\r\n* Refer [this](https://github.com/shagunsodhani/book-keeper) for sample values for Hadoop and HBase configurations in pseudo distributed mode and [this](docs/known-issues.md) for some known issues when setting up HBase. \r\n* Start Hadoop using `$HADOOP_HOME/sbin/start-dfs.sh` and HBase using `$HBASE_HOME/bin/start-hbase.sh`.\r\n* Verify that Hadoop and HBase are working propery by opening [http://localhost:50070/](http://localhost:50070/) and [http://localhost:16010/](http://localhost:16010/) respectively.\r\n* Copy `src/main/resources/reference.conf.sample` to `src/main/resources/reference.conf` and populate values.\r\n* Run `mvn clean install` in project folder.\r\n\r\n### To download dataset\r\n\r\n* Obtain an application token from [Socrata portal](https://dev.socrata.com/register) and copy it to `socrata.key` field in `reference.conf`.\r\n* Copy schema from `scripts/schema`.\r\n* Run `python scripts/scrapper/socrata.py`.\r\n\r\n### To load data in HDFS\r\n\r\n* Run `scala -cp target/uber-locis-0.0.1-SNAPSHOT.jar com.github.locis.apps.DataLoader <input_path_to_write_raw_data>`\r\n* If no path is provided, it writes to `/user/locis/input/data`\r\n\r\n### Dummy Dataset\r\n\r\n* A very small dataset (6 rows) can be found in `sampleData\\data` file. The file can be used for testing the different MapReduce tasks without having to download the socrata dataset. \r\n*Add the file to hdfs using the put command `$HADOOP_HOME/bin/hdfs dfs -put <path_to_locis>/sampleData/data <input_path_to_write_raw_data>` and proceed to run MapReduce tasks.\r\n\r\n### To run Neighbour Search MapReduce task\r\n\r\n* Run `$HADOOP_HOME/bin/hadoop jar target/uber-locis-0.0.1-SNAPSHOT.jar com.github.locis.apps.NeighborSearch <input_path_to_read_raw_data> <output_path_to_write_neighbors>`\r\n\r\n### To run Neighbour Grouping MapReduce task\r\n\r\n* Run `$HADOOP_HOME/bin/hadoop jar target/uber-locis-0.0.1-SNAPSHOT.jar com.github.locis.apps.NeighborGrouping <input_path_to_read_neighbors> <output_path_to_write_neighbor_groups>`\r\n\r\n### To run Count Instance MapReduce task\r\n\r\n* Run `$HADOOP_HOME/bin/hadoop jar target/uber-locis-0.0.1-SNAPSHOT.jar com.github.locis.apps.CountInstance <input_path_to_read_neighbor_groups> <output_path_to_write_instance_count>`\r\n\r\n### To run Colocation Pattern Search MapReduce task\r\n\r\n* Run `$HADOOP_HOME/bin/hadoop jar target/uber-locis-0.0.1-SNAPSHOT.jar com.github.locis.apps.PatternSearch <input_path_to_read_neighbor_groups> <output_path_to_write_prevalence_scores> <size_of_colocation>`\r\n\r\nNote that for running colocation pattern search task for size k, the results for size 1 to *k-1* should already be in the db. So to find colocation patterns of size *k*, run the script for 1 to *k* and not just *k*. This task can be easily automated using a bash script. \r\n\r\n### License\r\n\r\n[MIT](https://shagun.mit-license.org/)",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}